{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models, transforms\n",
    "from custom_dataset import CustomDataset\n",
    "from torchvision.models import resnet50, ResNet50_Weights, alexnet, AlexNet_Weights, vgg16, VGG16_Weights, squeezenet1_0, SqueezeNet1_0_Weights, densenet161, DenseNet161_Weights\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Załadowanie przetrenowanych modeli\n",
    "\n",
    "#Model resnet50\n",
    "model_resnet50 = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "num_ftrs = model_resnet50.fc.in_features\n",
    "model_resnet50.fc = nn.Linear(num_ftrs, 1) # zmiana liczby wyjść z 1000 na 1 \n",
    "\n",
    "# Model AlexNet\n",
    "model_alexnet = alexnet(weights=AlexNet_Weights.DEFAULT)\n",
    "num_ftrs = model_alexnet.classifier[6].in_features\n",
    "model_alexnet.classifier[6] = nn.Linear(num_ftrs, 1) \n",
    "\n",
    "# Model VGG16\n",
    "model_vgg16 = vgg16(weights=VGG16_Weights.DEFAULT)\n",
    "num_ftrs = model_vgg16.classifier[6].in_features\n",
    "model_vgg16.classifier[6] = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Model SqueezeNet\n",
    "model_squeezenet = squeezenet1_0(weights=SqueezeNet1_0_Weights.DEFAULT)\n",
    "model_squeezenet.classifier[1] = nn.Conv2d(512, 1, kernel_size=(1,1))\n",
    "model_squeezenet.num_classes = 1\n",
    "\n",
    "# Model DenseNet\n",
    "model_densenet = densenet161(weights=DenseNet161_Weights.DEFAULT)\n",
    "num_ftrs = model_densenet.classifier.in_features\n",
    "model_densenet.classifier = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Załadowanie danych \n",
    "\n",
    "# Augmentacja danych dla zbioru treningowego\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformacja dla zbiorów walidacyjnego i testowego\n",
    "transform = transforms.Compose([    \n",
    "    transforms.Resize((256, 256)),   #obraz 256x256     \n",
    "    transforms.CenterCrop(224), #wybór centralnej części obrazu o rozmiarze 224x224\n",
    "    transforms.ToTensor(), #konwersja obrazu do formatu tensora             \n",
    "    transforms.Normalize(              \n",
    "    mean=[0.485, 0.456, 0.406],        \n",
    "    std=[0.229, 0.224, 0.225] # normalizacja obrazu na podstawie średniej i odchylenia standardowego          \n",
    " )])\n",
    "\n",
    "dataset = CustomDataset('data/obrazy', 'data/etykiety', transform=transform)\n",
    "\n",
    "# Podział danych na treningowe i walidacyjne\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = int(0.15 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_dataset.dataset.transform = train_transforms\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.flatten() == labels.flatten()).sum().item()\n",
    "            predicted_labels.extend(predicted.tolist())\n",
    "            true_labels.extend(labels.tolist())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Trening własnego modelu\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  # Batch Normalization\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # druga warstwę konwolucyjną\n",
    "        self.bn2 = nn.BatchNorm2d(64)  # Batch Normalization\n",
    "        self.dropout = nn.Dropout(0.5) \n",
    "        self.pool = nn.MaxPool2d(2, 2) \n",
    "        self.fc1 = nn.Linear(64 * 56 * 56, 512)  # Zmieniono rozmiar wejścia\n",
    "        self.fc2 = nn.Linear(512, 1) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(nn.functional.relu(self.bn2(self.conv2(x))))  # Dodano warstwę i Batch Normalization\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Inicjalizacja modelu, funkcji straty i optymalizatora\n",
    "model = SimpleCNN()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "# Pętla treningowa\n",
    "\n",
    "dokladnosc_cnn = []\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad() # zerowanie gradientów w celu uniknięcia ich akumulacji\n",
    "        outputs = model(images) # obliczenie predykcji\n",
    "        loss = criterion(outputs, labels) # obliczenie straty \n",
    "        loss.backward() # propagacja wsteczna\n",
    "        optimizer.step() # aktualizacja wag\n",
    "        running_loss += loss.item() # aktualizacja straty\n",
    "\n",
    "    # Walidacja\n",
    "    model.eval() \n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad(): \n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images) \n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "    # Dokładność\n",
    "    accuracy = test_model(model, val_loader)\n",
    "    dokladnosc_cnn.append(accuracy)\n",
    "    print(f\"Epoka {epoch+1}, Strata treningowa: {(running_loss / len(train_loader)):.4f}, Strata walidacyjna: {(val_loss / len(val_loader)):.4f}, Dokładność: {(accuracy):.2f}%\")\n",
    "\n",
    "print(\"Trening zakończony\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Dokładność SimpleCNN na poszczególnych epokach\")\n",
    "plt.xlabel(\"Epoka\")\n",
    "plt.ylabel(\"Dokładność\")\n",
    "plt.plot(range(1, num_epochs+1), dokladnosc_cnn)\n",
    "plt.show()\n",
    "\n",
    "models_list = [model_resnet50, model_alexnet, model_vgg16, model_squeezenet, model_densenet, model]\n",
    "dokladnosc = []\n",
    "for model in models_list:\n",
    "    accuracy = test_model(model, test_loader)\n",
    "    dokladnosc.append(accuracy)\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Dokładność: {(accuracy):.2f}%\")\n",
    "\n",
    "print(dokladnosc)\n",
    "\n",
    "# Wykres dokładności modeli na zbiorze testowym \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Dokładność modeli na zbiorze testowym\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Dokładność\")\n",
    "plt.bar([\"ResNet50\", \"AlexNet\", \"VGG16\", \"SqueezeNet\", \"DenseNet\", \"SimpleCNN\"], dokladnosc)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
